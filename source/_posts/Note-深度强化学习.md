---
title: Note-深度强化学习
tags: []
password: 1aa45ed061f8f41b7292a435ae009b9e44b9d0dbc7b76cac50490f783956e667
thumbnail: ''
mathjax: true
toc: true
date: 2020-04-19 19:34:53
categories:
description:
---

# Deep Reinforcement Learning

## 定义

> 强化学习（Reinforcement Learning，RL），是指一类从**（与环境）交互中不断学习**的问题以及解决这类问题的方法. 强化学习问题可以描述为一个智能体从与环境的交互中不断学习以完成特定目标（比如取得最大奖励
> 值）. 和深度学习类似，强化学习中的关键问题也是贡献度分配问题，每一个动作并不能直接得到监督信息，需要通过整个模型的最终监督信息（奖励）得到，并且有一定的**延时**性.

**例子：**

- 多臂老虎机（Multi-Armed Bandit Problem）
- 悬崖行走

**两个对象：**

1. 智能体（Agent）可以感知外界**环境的状态**（State）和**反馈的奖励**（Reward），并进行**学习和决策**.
2. 环境（Environment）是智能体外部的所有事物，并受智能体**动作**的影响而**改变其状态**，并**反馈**给智能体相应的**奖励**.

**五个基本元素：**

1. 状态𝑠 是对环境的表示，可以是离散的或连续的，其状态空间为$\mathcal{S}$.
2. 动作𝑎 是对智能体的行为，可以是离散的或连续的，其动作空间为$\mathcal{A}$.
3. 策略𝜋(𝑎|𝑠) 是**智能体**根据环境状态𝑠 来决定下一步动作𝑎 的函数.
   - 确定性策略：𝜋 ∶ 𝒮 → 𝒜
   - 随机性策略：选择动作的概率分布𝜋(𝑎|𝑠) ≜ 𝑝(𝑎|𝑠)
   - 一般使用随机性策略. 随机性策略可以更好地探索环境，并具有多样性
4. 状态转移概率𝑝(𝑠′|𝑠, 𝑎) 是在**智能体**根据当前状态𝑠 做出一个动作𝑎 之后，环境在下一个时刻转变为状态𝑠′ 的概率.
5. 即时奖励𝑟(𝑠, 𝑎, 𝑠′) 是一个标量函数，即智能体根据当前状态𝑠 做出动作𝑎 之后，环境会反馈给智能体一个奖励，**这个奖励也经常和下一个时刻的状态𝑠′有关**.

